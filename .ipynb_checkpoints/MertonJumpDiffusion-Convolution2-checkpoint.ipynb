{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8c3434cb-5b10-4db7-82d7-07da2b331554"
    }
   },
   "outputs": [],
   "source": [
    "# Install Keras\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5defece0-7b7f-465c-a5dd-fa5a57b726cc"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy\n",
    "import random\n",
    "import decimal\n",
    "import scipy.linalg\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import numpy.random as nrand\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import itertools\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8815fd14-3654-4045-84ce-cd72de4620c9"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, model_from_json, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D, Conv2D, Input\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers.core import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "60177b25-bb89-4d37-9de6-f33bcbef2b92"
    }
   },
   "outputs": [],
   "source": [
    "class ModelParameters:\n",
    "    \"\"\"\n",
    "    Encapsulates model parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 all_time, all_delta, all_sigma, gbm_mu,\n",
    "                 jumps_lamda=0.0, jumps_sigma=0.0, jumps_mu=0.0):\n",
    "        \n",
    "        # This is the amount of time to simulate for\n",
    "        self.all_time = all_time\n",
    "        \n",
    "        # This is the delta, the rate of time e.g. 1/252 = daily, 1/12 = monthly\n",
    "        self.all_delta = all_delta\n",
    "        \n",
    "        # This is the volatility of the stochastic processes\n",
    "        # 0.001,1\n",
    "        self.all_sigma = all_sigma\n",
    "        \n",
    "        # This is the annual drift factor for geometric brownian motion\n",
    "        # -1,1\n",
    "        self.gbm_mu = gbm_mu\n",
    "        \n",
    "        # This is the probability of a jump happening at each point in time\n",
    "        #  0.0003,0.025\n",
    "        self.lamda = jumps_lamda\n",
    "        \n",
    "        # This is the volatility of the jump size\n",
    "        #   0.001, 1\n",
    "        self.jumps_sigma = jumps_sigma\n",
    "        \n",
    "        # This is the average jump size\n",
    "        # -0.1,0.1\n",
    "        self.jumps_mu = jumps_mu\n",
    "        \n",
    "\n",
    "def random_model_params():\n",
    "    \n",
    "    return ModelParameters(\n",
    "        # Fixed Parameters\n",
    "        all_time=2000,\n",
    "        all_delta=0.00396825396,\n",
    "        \n",
    "        # Random Parameters\n",
    "        \n",
    "        ### TODO: REDUCED SIGMA #######################\n",
    "        all_sigma = nrand.uniform(0.001,0.2),\n",
    "        ##############################################\n",
    "        \n",
    "        gbm_mu = nrand.uniform(-1,1),\n",
    "        jumps_lamda=nrand.uniform(0.0001,0.025),\n",
    "        jumps_sigma=nrand.uniform(0.001, 0.2),\n",
    "        jumps_mu=nrand.uniform(-0.5,0.5),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b3987838-5816-4f81-acbb-1be3612ce115"
    }
   },
   "outputs": [],
   "source": [
    "def plot_stochastic_processes(processes, title):\n",
    "    \"\"\"\n",
    "    This method plots a list of stochastic processes with a specified title\n",
    "    :return: plots the graph of the two\n",
    "    \"\"\"\n",
    "    plt.style.use(['bmh'])\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    ax.set_xlabel('Time, t')\n",
    "    ax.set_ylabel('Simulated Asset Price')\n",
    "    x_axis = numpy.arange(0, len(processes[0]), 1)\n",
    "    for i in range(len(processes)):\n",
    "        plt.plot(x_axis, processes[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "729ba020-4b53-457f-adb1-a05d66955ebb"
    }
   },
   "outputs": [],
   "source": [
    "def brownian_motion_log_returns(param):\n",
    "    \"\"\"\n",
    "    This method returns a Wiener process. The Wiener process is also called Brownian motion. For more information\n",
    "    about the Wiener process check out the Wikipedia page: http://en.wikipedia.org/wiki/Wiener_process\n",
    "    :param param: the model parameters object\n",
    "    :return: brownian motion log returns\n",
    "    \"\"\"\n",
    "    sqrt_delta_sigma = math.sqrt(param.all_delta) * param.all_sigma\n",
    "    return nrand.normal(loc=0, scale=sqrt_delta_sigma, size=param.all_time)\n",
    "\n",
    "def geometric_brownian_motion_log_returns(param):\n",
    "    \"\"\"\n",
    "    This method constructs a sequence of log returns which, when exponentiated, produce a random Geometric Brownian\n",
    "    Motion (GBM). GBM is the stochastic process underlying the Black Scholes options pricing formula.\n",
    "    :param param: model parameters object\n",
    "    :return: returns the log returns of a geometric brownian motion process\n",
    "    \"\"\"\n",
    "    assert isinstance(param, ModelParameters)\n",
    "    wiener_process = numpy.array(brownian_motion_log_returns(param))\n",
    "    sigma_pow_mu_delta = (param.gbm_mu - 0.5 * math.pow(param.all_sigma, 2.0)) * param.all_delta\n",
    "    return wiener_process + sigma_pow_mu_delta\n",
    "\n",
    "def jump_diffusion_process(param):\n",
    "    \"\"\"\n",
    "    This method produces a sequence of Jump Sizes which represent a jump diffusion process. These jumps are combined\n",
    "    with a geometric brownian motion (log returns) to produce the Merton model.\n",
    "    :param param: the model parameters object\n",
    "    :return: jump sizes for each point in time (mostly zeroes if jumps are infrequent)\n",
    "    \"\"\"\n",
    "    assert isinstance(param, ModelParameters)\n",
    "    s_n = time = 0\n",
    "    small_lamda = -(1.0 / param.lamda)\n",
    "    jump_sizes = np.zeros(param.all_time)\n",
    "    while s_n < param.all_time:\n",
    "        s_n += small_lamda * math.log(random.uniform(0, 1))\n",
    "        for j in range(0, param.all_time):\n",
    "            if time * param.all_delta <= s_n * param.all_delta <= (j + 1) * param.all_delta:\n",
    "                jump_sizes[j] += random.normalvariate(param.jumps_mu, param.jumps_sigma)\n",
    "                break\n",
    "        time += 1\n",
    "    return jump_sizes\n",
    "\n",
    "def geometric_brownian_motion_jump_diffusion_log_returns(param):\n",
    "    \"\"\"\n",
    "    This method constructs combines a geometric brownian motion process (log returns) with a jump diffusion process\n",
    "    (log returns) to produce a sequence of gbm jump returns.\n",
    "    :param param: model parameters object\n",
    "    :return: returns a GBM process with jumps in it\n",
    "    \"\"\"\n",
    "    assert isinstance(param, ModelParameters)\n",
    "    jump_diffusion = jump_diffusion_process(param)\n",
    "    geometric_brownian_motion = geometric_brownian_motion_log_returns(param)\n",
    "    return numpy.add(jump_diffusion, geometric_brownian_motion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    SSE = K.sum(K.square(y_true-y_pred))\n",
    "    SST = K.sum(K.square(y_true-K.mean(y_true)))\n",
    "    return 1-SSE/SST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aape(y_true, y_pred):\n",
    "    MSE = K.mean(K.abs((y_true-y_pred)/y_true))\n",
    "    return 100*MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2719ae90-dedf-4007-9bd7-016f9e69f102"
    }
   },
   "source": [
    "# Feedforward (using Moments & ACF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "48049aa6-0db6-4ece-8201-9d92967b221e"
    }
   },
   "outputs": [],
   "source": [
    "feedforward = Sequential()\n",
    "feedforward.add(Dense(2014, input_dim = 60, activation='elu'))\n",
    "feedforward.add(Dense(1024, activation='elu'))\n",
    "feedforward.add(Dense(512, activation='elu'))\n",
    "feedforward.add(Dense(256, activation='elu'))\n",
    "feedforward.add(Dense(128, activation='elu'))\n",
    "feedforward.add(Dense(64, activation='elu'))\n",
    "feedforward.add(Dense(32, activation='elu'))\n",
    "feedforward.add(Dense(16, activation='elu'))\n",
    "feedforward.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "5d841c52-db93-4aff-8e32-20190ba48949"
    }
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "feedforward.compile(loss='mse', optimizer='adam', metrics=[r2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "73777b08-64ab-42e8-a076-713766ce1df7"
    }
   },
   "source": [
    "I didn't normalise the training data. It took more than 60 epochs to train this network originally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7c311ada-91dd-4287-a60c-d8474a3095da"
    }
   },
   "outputs": [],
   "source": [
    "#feedforward.save(\"feedforward.h5\")\n",
    "feedforward = load_model(\"feedforward_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(all_time = 2000, paramset_size = 32, paths_p_paramset = 5):\n",
    "    while True:\n",
    "        RETURNS_ = []\n",
    "        PARAMS_ = []\n",
    "        \n",
    "        for i in range(paramset_size):\n",
    "            mp = random_model_params()\n",
    "            mp.all_time = all_time\n",
    "            \n",
    "            for j in range(paths_p_paramset):\n",
    "                PARAMS_.append(mp)\n",
    "                RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))\n",
    "        \n",
    "        train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "        \n",
    "        train_moments = [np.append(stats.moment(example, moment = range(2,20)), np.mean(example)) for example in RETURNS_]\n",
    "\n",
    "        train_statistics = np.array([np.append(train_moments[i], \n",
    "                              sm.tsa.stattools.acf(RETURNS_[i])) \n",
    "                    for i in range(len(RETURNS_))])\n",
    "\n",
    "        yield train_statistics, train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = batch_generator(paramset_size=10, paths_p_paramset=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a27578b2-14d5-4e94-b807-c597a9b5c597"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    print(str(i%9))\n",
    "    history = feedforward.fit_generator(train_gen, steps_per_epoch = 50, epochs = 1)\n",
    "    histories.append(history.history)\n",
    "    feedforward.save(\"feedforward_running_gen.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_1 = Input(batch_shape = (None, 60))\n",
    "\n",
    "layer1 = Dense(2048, activation='elu')(input_1)\n",
    "layer2 = Dense(1024, activation='elu')(layer1)\n",
    "\n",
    "layer3 = Dense(512, activation='elu')(layer2)\n",
    "layer4 = Dense(256, activation='elu')(layer3)\n",
    "\n",
    "layer5 = Dense(128, activation='elu')(layer4)\n",
    "layer6 = Dense(64, activation='elu')(layer5)\n",
    "\n",
    "layer7 = Dense(32, activation='elu')(layer5)\n",
    "last_layer = Dense(16, activation='elu')(layer7)\n",
    "\n",
    "output1 = Dense(1, name=\"sigma\")(last_layer)\n",
    "output2 = Dense(1, name=\"mu\")(last_layer)\n",
    "output3 = Dense(1, name=\"jump_sigma\")(last_layer)\n",
    "output4 = Dense(1, name=\"jump_mu\")(last_layer)\n",
    "output5 = Dense(1, name=\"lambda\")(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedforward = Model(input = input_1, output=[output1, output2, output3, output4, output5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "feedforward.compile(loss='mean_squared_error', optimizer='adam', metrics=[r2, 'mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedforward_CallBack = keras.callbacks.TensorBoard(log_dir='./feedforward', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(all_time = 2000, paramset_size = 32, paths_p_paramset = 5):\n",
    "    while True:\n",
    "        RETURNS_ = []\n",
    "        PARAMS_ = []\n",
    "        \n",
    "        for i in range(paramset_size):\n",
    "            mp = random_model_params()\n",
    "            mp.all_time = all_time\n",
    "            \n",
    "            for j in range(paths_p_paramset):\n",
    "                PARAMS_.append(mp)\n",
    "                RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))\n",
    "        \n",
    "        train_moments = [np.append(stats.moment(example, moment = range(2,20)), np.mean(example)) for example in RETURNS_]\n",
    "\n",
    "        train_statistics = np.array([np.append(train_moments[i], \n",
    "                              sm.tsa.stattools.acf(RETURNS_[i])) \n",
    "                    for i in range(len(RETURNS_))])\n",
    "        \n",
    "        sigmas = np.array([[mp.all_sigma] for mp in PARAMS_])\n",
    "        mus = np.array([[mp.gbm_mu] for mp in PARAMS_])\n",
    "        jump_sigmas = np.array([[mp.jumps_sigma] for mp in PARAMS_])\n",
    "        jump_mus = np.array([[mp.jumps_mu] for mp in PARAMS_])\n",
    "        lambdas = np.array([[mp.lamda] for mp in PARAMS_])\n",
    "        \n",
    "        yield train_statistics, [sigmas, mus, jump_sigmas, jump_mus, lambdas]\n",
    "\n",
    "train_gen = batch_generator(paramset_size=750, paths_p_paramset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedforward.load_weights(\"feedforward_running_gen_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda\n",
    "mp = ModelParameters(\n",
    "        # Fixed Parameters\n",
    "        all_time=2000,\n",
    "        all_delta=0.00396825396,\n",
    "        \n",
    "        # Random Parameters\n",
    "        \n",
    "        ### TODO: REDUCED SIGMA #######################\n",
    "        all_sigma = 0.1,\n",
    "        ##############################################\n",
    "        \n",
    "        gbm_mu = 0.05,\n",
    "        jumps_sigma=0.07,\n",
    "        jumps_mu=0.05,\n",
    "        jumps_lamda=0.02,\n",
    "    )\n",
    "test_set = []\n",
    "for i in range(1000):\n",
    "    if (i%100 == 0):\n",
    "        print(i)\n",
    "    test_set.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_moments = [np.append(stats.moment(example, moment = range(2,20)), np.mean(example)) for example in test_set]\n",
    "\n",
    "train_statistics2 = np.array([np.append(train_moments[i], \n",
    "                              sm.tsa.stattools.acf(test_set[i])) \n",
    "                    for i in range(len(test_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories2 = np.load(\"feedforward_mo_histories.npy\").tolist()\n",
    "ff_predicts = np.load(\"ff_predicts.npy\").tolist()\n",
    "#histories2 = []\n",
    "#ff_predicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/5 [=================>............] - ETA: 17s - loss: 0.0390 - sigma_loss: 0.0032 - mu_loss: 0.0220 - jump_sigma_loss: 0.0029 - jump_mu_loss: 0.0107 - lambda_loss: 2.0348e-04 - sigma_r2: 0.0139 - sigma_mean_absolute_percentage_error: 209.3983 - mu_r2: 0.9341 - mu_mean_absolute_percentage_error: 104.1217 - jump_sigma_r2: 0.1045 - jump_sigma_mean_absolute_percentage_error: 165.4292 - jump_mu_r2: 0.8685 - jump_mu_mean_absolute_percentage_error: 223.7965 - lambda_r2: -2.8353 - lambda_mean_absolute_percentage_error: 281.4311 "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    history = feedforward.fit_generator(train_gen, steps_per_epoch = 5, epochs = 1)\n",
    "    histories2.append(history.history)\n",
    "    ff_predicts.append(feedforward.predict(train_statistics2))\n",
    "    feedforward.save_weights(\"feedforward_running_gen_2.h5\")\n",
    "    \n",
    "    np.save(\"feedforward_mo_histories.npy\", histories2)\n",
    "    np.save(\"ff_predicts.npy\", ff_predicts)\n",
    "    \n",
    "    !git add --all\n",
    "    !git commit -am \"updated history, predictions and model\"\n",
    "    !git push -u origin master --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"feedforward_mo_histories.npy\", histories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_mean_absolute_percentage_error = []\n",
    "lambda_mean_absolute_percentage_error = []\n",
    "jump_sigma_mean_absolute_percentage_error = []\n",
    "jump_mu_mean_absolute_percentage_error = []\n",
    "mu_mean_absolute_percentage_error = []\n",
    "\n",
    "sigma_r2 = []\n",
    "lambda_r2 = []\n",
    "jump_sigma_r2 = []\n",
    "mu_r2 = []\n",
    "jump_mu_r2 = []\n",
    "\n",
    "jump_mu_loss = []\n",
    "lambda_loss = []\n",
    "sigma_loss = []\n",
    "mu_loss = []\n",
    "jump_sigma_loss = []\n",
    "\n",
    "loss = []\n",
    "\n",
    "for history in histories2:\n",
    "    sigma_mean_absolute_percentage_error.append(history['sigma_mean_absolute_percentage_error'])\n",
    "    lambda_mean_absolute_percentage_error.append(history['lambda_mean_absolute_percentage_error'])\n",
    "    jump_sigma_mean_absolute_percentage_error.append(history['jump_sigma_mean_absolute_percentage_error'])\n",
    "    jump_mu_mean_absolute_percentage_error.append(history['jump_mu_mean_absolute_percentage_error'])\n",
    "    mu_mean_absolute_percentage_error.append(history['mu_mean_absolute_percentage_error'])\n",
    "    \n",
    "    sigma_r2.append(history['sigma_r2'])\n",
    "    lambda_r2.append(history['lambda_r2'])\n",
    "    jump_sigma_r2.append(history['jump_sigma_r2'])\n",
    "    mu_r2.append(history['mu_r2'])\n",
    "    jump_mu_r2.append(history['jump_mu_r2'])\n",
    "    \n",
    "    jump_mu_loss.append(history['jump_mu_loss'])\n",
    "    lambda_loss.append(history['lambda_loss'])\n",
    "    sigma_loss.append(history['sigma_loss'])\n",
    "    mu_loss.append(history['mu_loss'])\n",
    "    jump_sigma_loss.append(history['jump_sigma_loss'])\n",
    "    \n",
    "    loss.append(history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mu_mean_absolute_percentage_error, label=\"Mu\")\n",
    "plt.plot(sigma_mean_absolute_percentage_error, label=\"Sigma\")\n",
    "plt.ylabel(\"Average Absolute Percentage Error (AAPE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.yscale('log')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_mean_absolute_percentage_error, label=\"Lambda\")\n",
    "plt.plot(jump_sigma_mean_absolute_percentage_error, label=\"Jumps - Sigma\")\n",
    "\n",
    "plt.ylabel(\"Average Absolute Percentage Error (AAPE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(jump_mu_mean_absolute_percentage_error, label=\"Jumps - Mu\")\n",
    "\n",
    "plt.ylabel(\"Average Absolute Percentage Error (AAPE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.yscale('log')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(mu_r2, label=\"Mu\")\n",
    "plt.plot(sigma_r2, label=\"Sigma\")\n",
    "plt.ylabel(\"R Squared\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([-1, 1])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lambda_r2, label=\"Lambda\")\n",
    "plt.plot(jump_sigma_r2, label=\"Jumps - Sigma\")\n",
    "plt.plot(jump_mu_r2, label=\"Jumps - Mu\")\n",
    "plt.ylabel(\"R Squared\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([-2, 1])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mu_loss, label=\"Mu\")\n",
    "plt.plot(sigma_loss, label=\"Sigma\")\n",
    "plt.plot(lambda_loss, label=\"Lambda\")\n",
    "plt.plot(jump_sigma_loss, label=\"Jumps - Sigma\")\n",
    "plt.plot(jump_mu_loss, label=\"Jumps - Mu\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward  RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_1 = Input(batch_shape = (None, 60))\n",
    "\n",
    "layer1 = Dense(2048, activation='relu')(input_1)\n",
    "layer2 = Dense(1024, activation='relu')(layer1)\n",
    "\n",
    "layer3 = Dense(512, activation='relu')(layer2)\n",
    "layer4 = Dense(256, activation='relu')(layer3)\n",
    "\n",
    "layer5 = Dense(128, activation='relu')(layer4)\n",
    "layer6 = Dense(64, activation='relu')(layer5)\n",
    "\n",
    "layer7 = Dense(32, activation='relu')(layer5)\n",
    "last_layer = Dense(16, activation='relu')(layer7)\n",
    "\n",
    "output1 = Dense(1, name=\"sigma\")(last_layer)\n",
    "output2 = Dense(1, name=\"mu\")(last_layer)\n",
    "output3 = Dense(1, name=\"jump_sigma\")(last_layer)\n",
    "output4 = Dense(1, name=\"jump_mu\")(last_layer)\n",
    "output5 = Dense(1, name=\"lambda\")(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedforward = Model(input = input_1, output=[output1, output2, output3, output4, output5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "feedforward.compile(loss='mean_squared_error', optimizer='adam', metrics=[r2, 'mean_absolute_percentage_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedforward_CallBack = keras.callbacks.TensorBoard(log_dir='./feedforward', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(all_time = 2000, paramset_size = 32, paths_p_paramset = 5):\n",
    "    while True:\n",
    "        RETURNS_ = []\n",
    "        PARAMS_ = []\n",
    "        \n",
    "        for i in range(paramset_size):\n",
    "            mp = random_model_params()\n",
    "            mp.all_time = all_time\n",
    "            \n",
    "            for j in range(paths_p_paramset):\n",
    "                PARAMS_.append(mp)\n",
    "                RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))\n",
    "        \n",
    "        train_moments = [np.append(stats.moment(example, moment = range(2,20)), np.mean(example)) for example in RETURNS_]\n",
    "\n",
    "        train_statistics = np.array([np.append(train_moments[i], \n",
    "                              sm.tsa.stattools.acf(RETURNS_[i])) \n",
    "                    for i in range(len(RETURNS_))])\n",
    "        \n",
    "        sigmas = np.array([[mp.all_sigma] for mp in PARAMS_])\n",
    "        mus = np.array([[mp.gbm_mu] for mp in PARAMS_])\n",
    "        jump_sigmas = np.array([[mp.jumps_sigma] for mp in PARAMS_])\n",
    "        jump_mus = np.array([[mp.jumps_mu] for mp in PARAMS_])\n",
    "        lambdas = np.array([[mp.lamda] for mp in PARAMS_])\n",
    "        \n",
    "        yield train_statistics, [sigmas, mus, jump_sigmas, jump_mus, lambdas]\n",
    "\n",
    "train_gen = batch_generator(paramset_size=250, paths_p_paramset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedforward.load_weights(\"feedforward_running_gen_2_relu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda\n",
    "mp = ModelParameters(\n",
    "        # Fixed Parameters\n",
    "        all_time=2000,\n",
    "        all_delta=0.00396825396,\n",
    "        \n",
    "        # Random Parameters\n",
    "        \n",
    "        ### TODO: REDUCED SIGMA #######################\n",
    "        all_sigma = 0.1,\n",
    "        ##############################################\n",
    "        \n",
    "        gbm_mu = 0.05,\n",
    "        jumps_sigma=0.07,\n",
    "        jumps_mu=0.05,\n",
    "        jumps_lamda=0.02,\n",
    "    )\n",
    "test_set = []\n",
    "for i in range(1000):\n",
    "    if (i%100 == 0):\n",
    "        print(i)\n",
    "    test_set.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_moments = [np.append(stats.moment(example, moment = range(2,20)), np.mean(example)) for example in test_set]\n",
    "\n",
    "train_statistics2 = np.array([np.append(train_moments[i], \n",
    "                              sm.tsa.stattools.acf(test_set[i])) \n",
    "                    for i in range(len(test_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories2_relu = np.load(\"feedforward_mo_histories_relu.npy\").tolist()\n",
    "ff_predicts_relu = np.load(\"ff_predicts_relu.npy\").tolist()\n",
    "#histories2_relu = []\n",
    "#ff_predicts_relu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    history = feedforward.fit_generator(train_gen, steps_per_epoch = 50, epochs = 1)\n",
    "    histories2_relu.append(history.history)\n",
    "    ff_predicts_relu.append(feedforward.predict(train_statistics2))\n",
    "    feedforward.save_weights(\"feedforward_running_gen_2_relu.h5\")\n",
    "    \n",
    "    np.save(\"feedforward_mo_histories_relu.npy\", histories2_relu)\n",
    "    np.save(\"ff_predicts_relu.npy\", ff_predicts_relu)\n",
    "    \n",
    "    !git add --all\n",
    "    !git commit -am \"updated history, predictions and model\"\n",
    "    #!git remote add origin https://RWMostert:N0ne\\ of\\ that.@github.com/RWMostert/Merton-Jump-Diffusion-Calibration-Tests.git\n",
    "    !git push -u origin master --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"feedforward_mo_histories.npy\", histories2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_mean_absolute_percentage_error = []\n",
    "lambda_mean_absolute_percentage_error = []\n",
    "jump_sigma_mean_absolute_percentage_error = []\n",
    "jump_mu_mean_absolute_percentage_error = []\n",
    "mu_mean_absolute_percentage_error = []\n",
    "\n",
    "sigma_r2 = []\n",
    "lambda_r2 = []\n",
    "jump_sigma_r2 = []\n",
    "mu_r2 = []\n",
    "jump_mu_r2 = []\n",
    "\n",
    "jump_mu_loss = []\n",
    "lambda_loss = []\n",
    "sigma_loss = []\n",
    "mu_loss = []\n",
    "jump_sigma_loss = []\n",
    "\n",
    "loss = []\n",
    "\n",
    "for history in histories2:\n",
    "    sigma_mean_absolute_percentage_error.append(history['sigma_mean_absolute_percentage_error'])\n",
    "    lambda_mean_absolute_percentage_error.append(history['lambda_mean_absolute_percentage_error'])\n",
    "    jump_sigma_mean_absolute_percentage_error.append(history['jump_sigma_mean_absolute_percentage_error'])\n",
    "    jump_mu_mean_absolute_percentage_error.append(history['jump_mu_mean_absolute_percentage_error'])\n",
    "    mu_mean_absolute_percentage_error.append(history['mu_mean_absolute_percentage_error'])\n",
    "    \n",
    "    sigma_r2.append(history['sigma_r2'])\n",
    "    lambda_r2.append(history['lambda_r2'])\n",
    "    jump_sigma_r2.append(history['jump_sigma_r2'])\n",
    "    mu_r2.append(history['mu_r2'])\n",
    "    jump_mu_r2.append(history['jump_mu_r2'])\n",
    "    \n",
    "    jump_mu_loss.append(history['jump_mu_loss'])\n",
    "    lambda_loss.append(history['lambda_loss'])\n",
    "    sigma_loss.append(history['sigma_loss'])\n",
    "    mu_loss.append(history['mu_loss'])\n",
    "    jump_sigma_loss.append(history['jump_sigma_loss'])\n",
    "    \n",
    "    loss.append(history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mu_mean_absolute_percentage_error, label=\"Mu\")\n",
    "plt.plot(sigma_mean_absolute_percentage_error, label=\"Sigma\")\n",
    "plt.ylabel(\"Average Absolute Percentage Error (AAPE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.yscale('log')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambda_mean_absolute_percentage_error, label=\"Lambda\")\n",
    "plt.plot(jump_sigma_mean_absolute_percentage_error, label=\"Jumps - Sigma\")\n",
    "\n",
    "plt.ylabel(\"Average Absolute Percentage Error (AAPE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(jump_mu_mean_absolute_percentage_error, label=\"Jumps - Mu\")\n",
    "\n",
    "plt.ylabel(\"Average Absolute Percentage Error (AAPE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.yscale('log')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(mu_r2, label=\"Mu\")\n",
    "plt.plot(sigma_r2, label=\"Sigma\")\n",
    "plt.ylabel(\"R Squared\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([-1, 1])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lambda_r2, label=\"Lambda\")\n",
    "plt.plot(jump_sigma_r2, label=\"Jumps - Sigma\")\n",
    "plt.plot(jump_mu_r2, label=\"Jumps - Mu\")\n",
    "plt.ylabel(\"R Squared\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylim([-2, 1])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mu_loss, label=\"Mu\")\n",
    "plt.plot(sigma_loss, label=\"Sigma\")\n",
    "plt.plot(lambda_loss, label=\"Lambda\")\n",
    "plt.plot(jump_sigma_loss, label=\"Jumps - Sigma\")\n",
    "plt.plot(jump_mu_loss, label=\"Jumps - Mu\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Single Paramter - MU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(batch_shape = (None, 60))\n",
    "\n",
    "layer1 = Dense(2048, activation='relu')(input_1)\n",
    "layer2 = Dense(1024, activation='relu')(layer1)\n",
    "\n",
    "dropout1 = Dropout(0.2)(layer2)\n",
    "\n",
    "layer3 = Dense(512, activation='relu')(dropout1)\n",
    "layer4 = Dense(256, activation='relu')(layer3)\n",
    "\n",
    "dropout2 = Dropout(0.2)(layer4)\n",
    "\n",
    "layer5 = Dense(128, activation='relu')(dropout2)\n",
    "layer6 = Dense(64, activation='relu')(layer5)\n",
    "\n",
    "dropout3 = Dropout(0.2)(layer6)\n",
    "\n",
    "layer7 = Dense(32, activation='relu')(dropout3)\n",
    "last_layer = Dense(16, activation='relu')(layer7)\n",
    "\n",
    "output2 = Dense(1, name=\"mu\")(last_layer)\n",
    "\n",
    "feedforward_mu = Model(input = input_1, output=[output2])\n",
    "# Compile model\n",
    "feedforward_mu.compile(loss='mean_squared_error', optimizer='adam', metrics=[r2, 'mean_absolute_percentage_error'])\n",
    "\n",
    "feedforward_mu_CallBack = keras.callbacks.TensorBoard(log_dir='./feedforward_mu', histogram_freq=0, write_graph=True, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(all_time = 2000, paramset_size = 32, paths_p_paramset = 5):\n",
    "    while True:\n",
    "        RETURNS_ = []\n",
    "        PARAMS_ = []\n",
    "        \n",
    "        for i in range(paramset_size):\n",
    "            mp = random_model_params()\n",
    "            mp.all_time = all_time\n",
    "            \n",
    "            for j in range(paths_p_paramset):\n",
    "                PARAMS_.append(mp)\n",
    "                RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))\n",
    "        \n",
    "        train_moments = [np.append(stats.moment(example, moment = range(2,20)), np.mean(example)) for example in RETURNS_]\n",
    "\n",
    "        train_statistics = np.array([np.append(train_moments[i], \n",
    "                              sm.tsa.stattools.acf(RETURNS_[i])) \n",
    "                    for i in range(len(RETURNS_))])\n",
    "        \n",
    "        mus = np.array([[mp.gbm_mu] for mp in PARAMS_])\n",
    "        \n",
    "        yield train_statistics, [mus]\n",
    "\n",
    "train_gen = batch_generator(paramset_size=10, paths_p_paramset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories_mu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    history = feedforward_mu.fit_generator(train_gen, steps_per_epoch = 250, epochs = 1)\n",
    "    histories_mu.append(history.history)\n",
    "    feedforward_mu.save_weights(\"feedforward_mu.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward with ReLu's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedforward = Sequential()\n",
    "feedforward.add(Dense(4096, input_dim = 60, activation='relu'))\n",
    "feedforward.add(Dense(1024, activation='relu'))\n",
    "feedforward.add(Dense(256, activation='relu'))\n",
    "feedforward.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "feedforward.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=[r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    print(str(i%9))\n",
    "    train_statistics = np.load(\"FF_Statistics_\"+str(i%9)+\".npy\")\n",
    "    train_targets = np.load(\"FF_Targets_\"+str(i%9)+\".npy\")\n",
    "    \n",
    "    feedforward.fit(np.array(train_statistics[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_statistics[80000:], train_targets[80000:]))\n",
    "    feedforward.save_weights(\"feedforward_running_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward with eLu's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feedforward = Sequential()\n",
    "feedforward.add(Dense(2014, input_dim = 60, activation='tanh'))\n",
    "feedforward.add(Dense(1024, activation='tanh'))\n",
    "feedforward.add(Dense(512, activation='tanh'))\n",
    "feedforward.add(Dense(256, activation='tanh'))\n",
    "feedforward.add(Dense(128, activation='tanh'))\n",
    "feedforward.add(Dense(64, activation='tanh'))\n",
    "feedforward.add(Dense(32, activation='tanh'))\n",
    "feedforward.add(Dense(16, activation='tanh'))\n",
    "feedforward.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "feedforward.compile(loss=\"mean_squared_error\", optimizer='adam', metrics=[r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    print(str(i%8))\n",
    "    train_statistics = np.load(\"FF_Statistics_\"+str(i%8)+\".npy\")\n",
    "    train_targets = np.load(\"FF_Targets_\"+str(i%8)+\".npy\")\n",
    "    \n",
    "    feedforward.fit(np.array(train_statistics[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_statistics[80000:], train_targets[80000:]))\n",
    "    feedforward.save_weights(\"feedforward_running_weights_elu_mape.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "23080745-c31e-462b-8e27-67b34eec54c9"
    }
   },
   "source": [
    "# 2D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1bef3e04-640c-490d-8e92-f6a7368b971d"
    }
   },
   "outputs": [],
   "source": [
    "covnet = Sequential()\n",
    "covnet.add(Convolution2D(40, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='tanh'))\n",
    "covnet.add(Convolution2D(40, 3, 3, activation='tanh', border_mode='same'))\n",
    "covnet.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet.add(Convolution2D(64, 3, 3, border_mode='same', activation='tanh'))\n",
    "covnet.add(Convolution2D(64, 3, 3, activation='tanh', border_mode='same'))\n",
    "covnet.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet.add(Convolution2D(128, 3, 3, border_mode='same', activation='tanh'))\n",
    "covnet.add(Convolution2D(128, 3, 3, activation='tanh', border_mode='same'))\n",
    "covnet.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet.add(Flatten())\n",
    "covnet.add(Dense(1024, activation='tanh'))\n",
    "covnet.add(Dense(512, activation='tanh'))\n",
    "covnet.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9f42cc64-3251-43ca-b9a1-5f4ece25fbe3"
    }
   },
   "outputs": [],
   "source": [
    "covnet.compile('adam', 'mean_squared_error', metrics=[r2, \"mean_absolute_percentage_error\"])\n",
    "#covnet.load_weights(\"covnet_mape_running.h5\")\n",
    "covnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "d9c79c54-36e2-4d61-ab91-0998258c57c3"
    }
   },
   "outputs": [],
   "source": [
    "covnet.load_weights(\"covnet_mse_tanh_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet.save(\"covnet_y.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "61720834-ecd5-406d-8024-7adc686f62bc"
    }
   },
   "outputs": [],
   "source": [
    "#RETURNS_, PARAMS_ = get_returns(2000)\n",
    "RETURNS_ = np.load(\"MertonReturns_2000_0.npy\")\n",
    "PARAMS_ = np.load(\"ModelParameters_2000_0.npy\")\n",
    "train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "00d088ee-de8c-47f5-a97d-560265ba9351"
    }
   },
   "outputs": [],
   "source": [
    "random_permute = np.random.permutation(len(train_data))\n",
    "train_data = train_data[random_permute]\n",
    "train_targets = train_targets[random_permute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "af8000f3-742a-4a82-ba61-f46e4ca45edc"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = covnet.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    covnet.save_weights(\"covnet_mse_tanh.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mp = random_model_params()\n",
    "mp.all_time = 2000\n",
    "\n",
    "mp.all_sigma = 0.1\n",
    "mp.gbm_mu = 0.05\n",
    "mp.jumps_sigma = 0.07\n",
    "mp.jumps_mu = 0.05\n",
    "mp.jumps_lamda = 0.02\n",
    "RETURNS_ = [geometric_brownian_motion_jump_diffusion_log_returns(mp) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = np.reshape(np.array(RETURNS_), (1000, 40, 50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = covnet.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions, axis = 0)-1.96*np.std(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(all_time = 2000, paramset_size = 32, paths_p_paramset = 5):\n",
    "    while True:\n",
    "        RETURNS_ = []\n",
    "        PARAMS_ = []\n",
    "        \n",
    "        for i in range(paramset_size):\n",
    "            mp = random_model_params()\n",
    "            mp.all_time = all_time\n",
    "            \n",
    "            for j in range(paths_p_paramset):\n",
    "                PARAMS_.append(mp)\n",
    "                RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))\n",
    "        \n",
    "        train_data = np.reshape(np.array(RETURNS_), (paramset_size*paths_p_paramset, 40, 50, 1))\n",
    "        train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "        yield train_data, train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = batch_generator(paramset_size=1, paths_p_paramset=10)\n",
    "valid_gen = batch_generator(paramset_size=1, paths_p_paramset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    #history = covnet.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), batch_size=100, nb_epoch=1, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    history = covnet.fit_generator(train_gen, samples_per_epoch = 1000, nb_epoch = 30)\n",
    "    covnet.save(\"2dCovnet_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b977080c-be8d-446e-b87f-f429e8b88338"
    }
   },
   "outputs": [],
   "source": [
    "covnet.save(\"covnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b03bcfcc-15dc-4f4f-9aef-1fbe7f71d791"
    }
   },
   "outputs": [],
   "source": [
    "predictions = covnet_mo.predict(train_data[80000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3ff38326-7cf8-4796-a6fd-f05827ad612d"
    }
   },
   "outputs": [],
   "source": [
    "parameter_MSEs = []\n",
    "for p in range(train_targets.shape[1]):\n",
    "    prediction_set = predictions[:,p]\n",
    "    actual_values = np.array(train_targets)[80000:,p]\n",
    "    error = prediction_set - actual_values\n",
    "    squared_error = np.square(error)\n",
    "    parameter_MSEs.append(np.average(squared_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "1c8753ad-2820-4eae-b627-6b7738b6dda2"
    }
   },
   "outputs": [],
   "source": [
    " mp = ModelParameters(\n",
    "        all_time=2000,\n",
    "        all_delta=0.00396825396,                   \n",
    "        all_sigma = 0.2,\n",
    "        gbm_mu = 0.05,\n",
    "        jumps_lamda=0.07,\n",
    "        jumps_sigma=0.03,\n",
    "        jumps_mu=0.005,\n",
    "    )\n",
    "#mp = random_model_params()\n",
    "\n",
    "target = np.array([mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda])\n",
    "\n",
    "returns_0 = geometric_brownian_motion_jump_diffusion_log_returns(mp)\n",
    "ret = np.reshape(np.array(returns_0), (40, 50, 1))\n",
    "\n",
    "prediction_0 = covnet.predict(np.array([ret]))\n",
    "print(\"Parameters:        sigma,    mu,  sigma_j, mu_j, lambda_j\")\n",
    "print(\"True Value:       \", np.round(target, decimals=4))\n",
    "print(\"-----------\")\n",
    "print(\"Predicted:        \", np.round(prediction_0[0], decimals=4))\n",
    "print(\"Upper confidence: \", np.round(target+1.96*np.sqrt(parameter_MSEs), decimals=4))\n",
    "print(\"Lower confidence: \", np.round(target-1.96*np.sqrt(parameter_MSEs), decimals=4))\n",
    "print(\"::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e6aa3f35-f861-4052-b7ae-1e0fa2305615"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'True Values:' : target,\n",
    "     'Predicted:' : prediction_0[0],\n",
    "    'Upper 95% Confidence:' : target+1.96*np.sqrt(parameter_MSEs),\n",
    "    'Lower 95% Confidence:' : target-1.96*np.sqrt(parameter_MSEs)}\n",
    "\n",
    "df = pd.DataFrame(d, index=['sigma', 'mu', 'jumps_sigma', 'jumps_mu', 'jumps_lambda'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUAN SE CONVNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juan_covnet = load_model(\"convnet_2D.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 50, 40, 1))\n",
    "    train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = covnet.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    covnet.save_weights(\"convnet_2D.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda\n",
    "\n",
    "mp = random_model_params()\n",
    "mp.all_time = 2000\n",
    "\n",
    "mp.all_sigma = 0.1\n",
    "mp.gbm_mu = 0.05\n",
    "mp.jumps_sigma = 0.07\n",
    "mp.jumps_mu = 0.05\n",
    "mp.lamda = 0.025\n",
    "\n",
    "RETURNS_ = []\n",
    "for i in range(1000):\n",
    "    if i%100 == 0: \n",
    "        print(i)\n",
    "    RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.reshape(np.array(RETURNS_), (1000, 40, 50, 1))\n",
    "predictions = covnet_mo.predict(dataset)\n",
    "np.median(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions, axis = 1) + 1.96*np.std(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov2 = Sequential()\n",
    "cov2.add(Convolution2D(40, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='relu'))\n",
    "cov2.add(Convolution2D(40, 3, 3, activation='relu', border_mode='same'))\n",
    "cov2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov2.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "cov2.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "cov2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov2.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "cov2.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "cov2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov2.add(Flatten())\n",
    "cov2.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov2.compile('adam', 'mse', metrics=[r2])\n",
    "cov2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov2 = load_model(\"cov2_y_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = cov2.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    cov2.save(\"cov2_y_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Covnet 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov3 = Sequential()\n",
    "cov3.add(Convolution2D(128, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='relu'))\n",
    "cov3.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "cov3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov3.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "cov3.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "cov3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov3.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu'))\n",
    "cov3.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same'))\n",
    "cov3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov3.add(Flatten())\n",
    "cov3.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov3.compile('adam', 'mse', metrics=[r2])\n",
    "cov3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = cov3.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    cov3.save(\"cov3_y_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnet 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov4 = Sequential()\n",
    "cov4.add(Convolution2D(128, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='elu'))\n",
    "cov4.add(Convolution2D(128, 3, 3, activation='elu', border_mode='same'))\n",
    "cov4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov4.add(Convolution2D(64, 3, 3, border_mode='same', activation='elu'))\n",
    "cov4.add(Convolution2D(64, 3, 3, activation='elu', border_mode='same'))\n",
    "cov4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov4.add(Convolution2D(32, 3, 3, border_mode='same', activation='elu'))\n",
    "cov4.add(Convolution2D(32, 3, 3, activation='elu', border_mode='same'))\n",
    "cov4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov4.add(Flatten())\n",
    "cov4.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov4.compile('adam', 'mse', metrics=[r2])\n",
    "cov4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov4 = load_model(\"cov4_y_running.h5\")\n",
    "cov4CallBack = keras.callbacks.TensorBoard(log_dir='./Cov4', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    \n",
    "    history = cov4.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]), callbacks=[cov4CallBack])\n",
    "    cov4.save(\"cov4_y_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnet 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov5 = Sequential()\n",
    "cov5.add(Convolution2D(16, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='relu'))\n",
    "cov5.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same'))\n",
    "cov5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov5.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "cov5.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "cov5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov5.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "cov5.add(Convolution2D(512, 3, 3, activation='relu', border_mode='same'))\n",
    "cov5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov5.add(Flatten())\n",
    "cov5.add(Dense(512))\n",
    "cov5.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov5.compile('adam', 'mse', metrics=[r2])\n",
    "cov5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov5 = load_model(\"cov5_y_running.h5\")\n",
    "cov5.summary()\n",
    "cov5CallBack = keras.callbacks.TensorBoard(log_dir='./Cov5', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    \n",
    "    history = cov5.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]), callbacks=[cov5CallBack])\n",
    "    cov5.save(\"cov5_y_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Covnet 6 - Add Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov6 = Sequential()\n",
    "cov6.add(Convolution2D(16, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='relu'))\n",
    "cov6.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same'))\n",
    "cov6.add(Dropout(0.2))\n",
    "cov6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov6.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "cov6.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "cov6.add(Dropout(0.2))\n",
    "cov6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov6.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "cov6.add(Convolution2D(512, 3, 3, activation='relu', border_mode='same'))\n",
    "cov6.add(Dropout(0.2))\n",
    "cov6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "cov6.add(Flatten())\n",
    "cov6.add(Dense(512))\n",
    "cov6.add(Dense(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov6.compile('adam', 'mse', metrics=['accuracy'])\n",
    "cov6.summary()\n",
    "cov6CallBack = keras.callbacks.TensorBoard(log_dir='./Cov6', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    \n",
    "    history = cov6.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]), callbacks=[cov6CallBack])\n",
    "    #history = cov6.fit(np.array(train_data[:80]), np.array(train_targets[:80]), nb_epoch=150, batch_size=80)\n",
    "    cov6.save(\"cov6_y_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Single Parameter Prediction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_sp = Sequential()\n",
    "covnet_sp.add(Convolution2D(32, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='relu'))\n",
    "covnet_sp.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "covnet_sp.add(MaxPooling2D(pool_size=(4,4)))\n",
    "\n",
    "covnet_sp.add(Flatten())\n",
    "covnet_sp.add(Reshape(target_shape = (7680, 1)))\n",
    "covnet_sp.add(Dense(32, activation='relu'))\n",
    "covnet_sp.add(LSTM(16, name=\"LSTM_10\"))\n",
    "covnet_sp.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covnet_sp.compile('adam', 'mse', metrics=[aape, r2])\n",
    "covnet_sp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.jumps_mu] for mp in PARAMS_])\n",
    "\n",
    "    history = covnet_sp.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=10, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    covnet_sp.save_weights(\"covnet_sp_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnet Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_lambda = Sequential()\n",
    "covnet_lambda.add(Convolution2D(40, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='relu'))\n",
    "covnet_lambda.add(Convolution2D(40, 3, 3, activation='relu', border_mode='same'))\n",
    "covnet_lambda.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet_lambda.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "covnet_lambda.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "covnet_lambda.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet_lambda.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "covnet_lambda.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "covnet_lambda.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet_lambda.add(Flatten())\n",
    "covnet_lambda.add(Dense(1024, activation='relu'))\n",
    "covnet_lambda.add(Dense(512, activation='relu'))\n",
    "covnet_lambda.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covnet_lambda.compile('adam', 'mse', metrics=['accuracy', aape, r2])\n",
    "covnet_lambda.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_lambda.load_weights(\"covnet_lambda_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = covnet_lambda.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    covnet_lambda.save_weights(\"covnet_lambda_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mp = random_model_params()\n",
    "mp.all_time = 2000\n",
    "\n",
    "mp.all_sigma = 0.2\n",
    "mp.gbm_mu = 0.05\n",
    "mp.jumps_sigma = 0.07\n",
    "mp.jumps_mu = 0.05\n",
    "mp.lamda = 0.3\n",
    "\n",
    "RETURNS_ = []\n",
    "for i in range(1000):\n",
    "    print(i)\n",
    "    RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = np.reshape(np.array(RETURNS_), (1000, 40, 50, 1))\n",
    "predictions = covnet_lambda.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions, axis = 0)+1.96*np.std(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(predictions, axis = 0)-1.96*np.std(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnet Jumps Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_jumpsigma = Sequential()\n",
    "covnet_jumpsigma.add(Convolution2D(40, 3, 3, input_shape=(40, 50, 1), border_mode='same', activation='relu'))\n",
    "covnet_jumpsigma.add(Convolution2D(40, 3, 3, activation='relu', border_mode='same'))\n",
    "covnet_jumpsigma.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet_jumpsigma.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "covnet_jumpsigma.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "covnet_jumpsigma.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet_jumpsigma.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "covnet_jumpsigma.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "covnet_jumpsigma.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "covnet_jumpsigma.add(Flatten())\n",
    "covnet_jumpsigma.add(Dense(1024, activation='relu'))\n",
    "covnet_jumpsigma.add(Dense(512, activation='relu'))\n",
    "covnet_jumpsigma.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covnet_jumpsigma.compile('adam', 'mse', metrics=['accuracy', aape, r2])\n",
    "covnet_jumpsigma.summary()\n",
    "covnet_jumpsigma.load_weights(\"covnet_jumpsigma_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    train_targets = np.array([[mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = covnet_jumpsigma.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    covnet_jumpsigma.save_weights(\"covnet_jumpsigma_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnet for Mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_mu = Sequential()\n",
    "net_mu.add(Dense(32, input_dim=2000, activation='relu'))\n",
    "net_mu.add(Dense(16, activation='relu'))\n",
    "net_mu.add(Dense(8, activation='relu'))\n",
    "net_mu.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_mu.compile('adam', 'mse', metrics=['accuracy', aape, r2])\n",
    "net_mu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 2000))\n",
    "    train_targets = np.array([[mp.gbm_mu] for mp in PARAMS_])\n",
    "\n",
    "    history = net_mu.fit(np.array(train_data[:80000]), np.array(train_targets[:80000]), nb_epoch=1, batch_size=100, validation_data=(train_data[80000:], train_targets[80000:]))\n",
    "    net_mu.save_weights(\"net_mu_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_sigma = Sequential()\n",
    "net_sigma.add(Dense(1024, input_dim=2000, activation='relu'))\n",
    "net_sigma.add(Dense(512, activation='relu'))\n",
    "net_sigma.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_sigma.compile('adam', 'mse', metrics=['accuracy', aape, r2])\n",
    "net_sigma.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Covnet Multiple Output prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape = (40, 50, 1))\n",
    "\n",
    "layer1 = Convolution2D(32, 12, 12, border_mode='same', activation='relu')(input_1)\n",
    "layer2 = Convolution2D(32, 12, 12, activation='relu', border_mode='same')(layer1)\n",
    "layer3 = MaxPooling2D(pool_size=(2,2))(layer2)\n",
    "\n",
    "layer4 = Convolution2D(64, 6, 6, border_mode='same', activation='relu')(layer3)\n",
    "layer5 = Convolution2D(64, 6, 6, activation='relu', border_mode='same')(layer4)\n",
    "layer6 = MaxPooling2D(pool_size=(2,2))(layer5)\n",
    "\n",
    "layer7 = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(layer6)\n",
    "layer8 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(layer7)\n",
    "layer9 = MaxPooling2D(pool_size=(2,2))(layer8)\n",
    "\n",
    "flatten = Flatten()(layer9)\n",
    "last_layer = Dense(256, activation='relu')(flatten)\n",
    "output1 = Dense(1, name=\"sigma\")(last_layer)\n",
    "output2 = Dense(1, name=\"mu\")(last_layer)\n",
    "output3 = Dense(1, name=\"jump_sigma\")(last_layer)\n",
    "output4 = Dense(1, name=\"jump_mu\")(last_layer)\n",
    "output5 = Dense(1, name=\"lambda\")(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covnet_mo = Model(input = input_1, output=[output1, output2, output3, output4, output5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covnet_mo.compile('adam', 'mean_squared_error', metrics=['mean_absolute_percentage_error', r2])\n",
    "covnet_mo.summary()\n",
    "covnet_mo.load_weights(\"covnet_multiple_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_mo_CallBack = keras.callbacks.TensorBoard(log_dir='./Cov_MO', histogram_freq=0, write_graph=True, write_images=True)\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(all_time = 2000, paramset_size = 32, paths_p_paramset = 5):\n",
    "    while True:\n",
    "        RETURNS_ = []\n",
    "        PARAMS_ = []\n",
    "        \n",
    "        for i in range(paramset_size):\n",
    "            mp = random_model_params()\n",
    "            mp.all_time = all_time\n",
    "            \n",
    "            for j in range(paths_p_paramset):\n",
    "                PARAMS_.append(mp)\n",
    "                RETURNS_.append(geometric_brownian_motion_jump_diffusion_log_returns(mp))\n",
    "        \n",
    "        train_data = np.reshape(np.array(RETURNS_), (paramset_size*paths_p_paramset, 40, 50, 1))\n",
    "        sigmas = np.array([[mp.all_sigma] for mp in PARAMS_])\n",
    "        mus = np.array([[mp.gbm_mu] for mp in PARAMS_])\n",
    "        jump_sigmas = np.array([[mp.jumps_sigma] for mp in PARAMS_])\n",
    "        jump_mus = np.array([[mp.jumps_mu] for mp in PARAMS_])\n",
    "        lambdas = np.array([[mp.lamda] for mp in PARAMS_])\n",
    "            \n",
    "        #train_targets = np.array([[mp.all_sigma, mp.gbm_mu, mp.jumps_sigma, mp.jumps_mu, mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "        yield train_data, [sigmas, mus, jump_sigmas, jump_mus, lambdas]\n",
    "\n",
    "train_gen = batch_generator(paramset_size=10, paths_p_paramset=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE HERE HERE HERE HERE\n",
    "\n",
    "for i in range(150):\n",
    "    #RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    #PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    #train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    \n",
    "    covnet_mo.fit_generator(train_gen, steps_per_epoch = 300, epochs = 1)\n",
    "\n",
    "    #history = covnet_mo.fit(np.array(train_data), [sigmas, mus, jump_sigmas, jump_mus, lambdas], nb_epoch=1, batch_size=100, callbacks=[covnet_mo_CallBack])\n",
    "    #histories.append(history)\n",
    "    covnet_mo.save_weights(\"covnet_multiple_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Covnet Multiple Output 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_1 = Input(shape = (40, 50, 1))\n",
    "\n",
    "layer1 = Convolution2D(40, 3, 3, border_mode='same', activation='relu')(input_1)\n",
    "layer2 = Convolution2D(40, 3, 3, activation='relu', border_mode='same')(layer1)\n",
    "layer3 = MaxPooling2D(pool_size=(2,2))(layer2)\n",
    "\n",
    "layer4 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(layer3)\n",
    "layer5 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(layer4)\n",
    "layer6 = MaxPooling2D(pool_size=(2,2))(layer5)\n",
    "\n",
    "layer7 = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(layer6)\n",
    "layer8 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(layer7)\n",
    "layer9 = MaxPooling2D(pool_size=(2,2))(layer8)\n",
    "\n",
    "flatten = Flatten()(layer9)\n",
    "last_layer = Dense(256, activation='relu')(flatten)\n",
    "output1 = Dense(1, name=\"sigma\")(last_layer)\n",
    "output2 = Dense(1, name=\"mu\")(last_layer)\n",
    "output3 = Dense(1, name=\"jump_sigma\")(last_layer)\n",
    "output4 = Dense(1, name=\"jump_mu\")(last_layer)\n",
    "output5 = Dense(1, name=\"lambda\")(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_mo = Model(input = input_1, output=[output1, output2, output3, output4, output5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covnet_mo.compile('adam', 'mse', metrics=['accuracy', aape, r2])\n",
    "covnet_mo.summary()\n",
    "covnet_mo.load_weights(\"covnet_mo_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_mo2_CallBack = keras.callbacks.TensorBoard(log_dir='./Cov_MO2', histogram_freq=0, write_graph=True, write_images=True)\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    \n",
    "    sigmas = np.array([[mp.all_sigma] for mp in PARAMS_])\n",
    "    mus = np.array([[mp.gbm_mu] for mp in PARAMS_])\n",
    "    jump_sigmas = np.array([[mp.jumps_sigma] for mp in PARAMS_])\n",
    "    jump_mus = np.array([[mp.jumps_mu] for mp in PARAMS_])\n",
    "    lambdas = np.array([[mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = covnet_mo.fit(np.array(train_data), [sigmas, mus, jump_sigmas, jump_mus, lambdas], nb_epoch=1, batch_size=100, callbacks=[covnet_mo2_CallBack])\n",
    "    histories.append(history)\n",
    "    covnet_mo.save_weights(\"covnet_mo_running.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covnet Multiple Output 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_1 = Input(shape = (40, 50, 1))\n",
    "\n",
    "layer1 = Convolution2D(40, 3, 3, border_mode='same', activation='relu', name=\"conv_1\")(input_1)\n",
    "layer2 = Convolution2D(40, 3, 3, activation='relu', border_mode='same', name=\"conv_2\")(layer1)\n",
    "layer3 = MaxPooling2D(pool_size=(2,2), name=\"pool_3\")(layer2)\n",
    "\n",
    "layer4 = Convolution2D(64, 3, 3, border_mode='same', activation='relu', name=\"conv_4\")(layer3)\n",
    "layer5 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name=\"conv_5\")(layer4)\n",
    "layer6 = MaxPooling2D(pool_size=(2,2), name=\"pool_6\")(layer5)\n",
    "\n",
    "layer7 = Convolution2D(128, 3, 3, border_mode='same', activation='relu', name=\"conv_7\")(layer6)\n",
    "layer8 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name=\"conv_8\")(layer7)\n",
    "layer9 = MaxPooling2D(pool_size=(2,2), name=\"pool_9\")(layer8)\n",
    "\n",
    "flatten = Flatten()(layer9)\n",
    "reshaped = Reshape(target_shape = (3840, 1))(flatten)\n",
    "lstm = LSTM(64, name=\"LSTM_10\")(reshaped)\n",
    "last_layer = Dense(256, activation='relu', name=\"Dense_11\")(lstm)\n",
    "output1 = Dense(1, name=\"sigma\")(last_layer)\n",
    "output2 = Dense(1, name=\"mu\")(last_layer)\n",
    "output3 = Dense(1, name=\"jump_sigma\")(last_layer)\n",
    "output4 = Dense(1, name=\"jump_mu\")(last_layer)\n",
    "output5 = Dense(1, name=\"lambda\")(last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_mo = Model(input = input_1, output=[output1, output2, output3, output4, output5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covnet_mo.compile('adam', 'mse', metrics=['accuracy', aape, r2])\n",
    "covnet_mo.summary()\n",
    "#covnet_mo.load_weights(\"covnet_mo_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covnet_mo3_CallBack = keras.callbacks.TensorBoard(log_dir='./Cov_MO3', histogram_freq=0, write_graph=True, write_images=True)\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(150):\n",
    "    RETURNS_ = np.load(\"MertonReturns_2000_\"+str(7-i%8)+\".npy\")\n",
    "    PARAMS_ = np.load(\"ModelParameters_2000_\"+str(7-i%8)+\".npy\")\n",
    "    train_data = np.reshape(np.array(RETURNS_), (100000, 40, 50, 1))\n",
    "    \n",
    "    sigmas = np.array([[mp.all_sigma] for mp in PARAMS_])\n",
    "    mus = np.array([[mp.gbm_mu] for mp in PARAMS_])\n",
    "    jump_sigmas = np.array([[mp.jumps_sigma] for mp in PARAMS_])\n",
    "    jump_mus = np.array([[mp.jumps_mu] for mp in PARAMS_])\n",
    "    lambdas = np.array([[mp.lamda] for mp in PARAMS_])\n",
    "\n",
    "    history = covnet_mo.fit(np.array(train_data), [sigmas, mus, jump_sigmas, jump_mus, lambdas], nb_epoch=1, batch_size=100, callbacks=[covnet_mo3_CallBack])\n",
    "    histories.append(history)\n",
    "    covnet_mo.save_weights(\"covnet_mo3_running.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "nbpresent": {
   "slides": {
    "9df90948-6817-4be2-9c21-0f8c1bd3f925": {
     "id": "9df90948-6817-4be2-9c21-0f8c1bd3f925",
     "layout": "grid",
     "prev": null,
     "regions": {
      "6ed85853-99d7-4f9d-a56e-06a7bd54a954": {
       "attrs": {
        "height": 0.3333333333333333,
        "pad": 0.01,
        "treemap:weight": 1,
        "width": 1,
        "x": 0,
        "y": 0.6666666666666666
       },
       "content": {
        "cell": "af8000f3-742a-4a82-ba61-f46e4ca45edc",
        "part": "source"
       },
       "id": "6ed85853-99d7-4f9d-a56e-06a7bd54a954"
      },
      "fe19646f-ac4b-45b8-98f8-534ca6297f01": {
       "attrs": {
        "height": 0.6666666666666666,
        "pad": 0.01,
        "treemap:weight": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "3ff38326-7cf8-4796-a6fd-f05827ad612d",
        "part": "source"
       },
       "id": "fe19646f-ac4b-45b8-98f8-534ca6297f01"
      }
     },
     "theme": null
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
